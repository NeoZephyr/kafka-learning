## 消息队列使用场景
### 异步处理
1. 更快地返回结果
2. 减少等待，实现步骤之间的并发，提升系统总体的性能

### 流量控制
使用消息队列隔离网关和后端服务。网关在收到请求后，将请求放入请求消息队列，后端服务从请求消息队列中获取请求，完成后续处理过程，然后返回结果。对于超时的请求，后端服务可以直接丢弃

运维人员还可以随时增加后端服务的实例数量进行水平扩容，达到削峰填谷的作用。但这样做同样有以下缺点：
1. 增加了系统调用链环节，导致总体的响应时延变长
2. 上下游系统都要将同步调用改为异步消息，增加了系统的复杂度

如果能预估出后端服务的处理能力，就可以用消息队列实现一个令牌桶，更简单地进行流量控制：

单位时间内发放固定数量的令牌到令牌桶中，服务在处理请求之前必须先从令牌桶中拿出一个令牌，如果令牌桶中没有令牌，则拒绝请求。这样就保证单位时间内，能处理的请求不超过发放令牌的数量，起到了流量控制的作用

使用令牌桶，不需要破坏原有的调用链，只要网关在处理请求时增加一个获取令牌的逻辑。令牌桶可以简单地用一个有固定容量的消息队列加一个令牌发生器来实现：令牌发生器按照预估的处理能力，匀速生产令牌并放入令牌队列（如果队列满了则丢弃令牌）。网关在收到请求时去令牌队列消费一个令牌，获取到令牌则继续调用后端服务，如果获取不到令牌则直接返回失败

### 服务解耦


## 消息队列选择
### 消息队列要求
消息的可靠传递：确保不丢消息
支持集群：确保不会因为某个节点宕机导致服务不可用
性能：满足绝大多数场景的性能要求

### RabbitMQ
1. 对消息堆积的支持不好，当大量消息积压的时候，会导致 RabbitMQ 的性能急剧下降
2. 性能相较于其他消息队列而言很差。依据硬件配置的不同，大概每秒钟只能处理几万到十几万条消息
3. 使用的编程语言非常小众

### RocketMQ
1. RocketMQ 的性能比 RabbitMQ 要高一个数量级，每秒钟大概能处理几十万条消息
2. 对在线业务的响应时延做了很多的优化
3. 相比较而言，在国际上还没有那么流行，与周边生态系统的集成和兼容程度要略逊一筹

### Kafka
1. 与周边生态系统的兼容性好
2. Kafka 的性能，尤其是异步收发的性能非常好
3. 异步批量的设计会导致同步收发消息的响应时延比较高，因为当客户端发送一条消息的时候，Kafka 并不会立即发送出去，而是攒一批再发送。如果业务场景中，每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高。因此，不太适合在线业务场景


## 消息队列与事务
消息队列中的事务，主要解决消息生产者和消息消费者的数据一致性问题

消息队列实现分布式事务：
1. 在消息队列上开启一个事务
2. 向消息服务器发送一个半消息（半消息和普通消息的唯一区别是，在事务提交之前，对于消费者来说，这个消息是不可见的）
3. 半消息发送成功后，执行本地事务
4. 根据本地事务的执行结果决定提交或者回滚事务消息
5. 如果提交事务消息，下游系统消费消息继续后续流程
6. 如果回滚事务消息，下游系统就不会再收到这条消息

如果提交事务消息时失败，Kafka 直接抛出异常，我们可以在业务代码中反复重试提交，直到提交成功，或者删除之前创建的订单进行补偿

在 RocketMQ 中的事务实现中，如果生产者在提交或者回滚事务消息时发生网络异常，RocketMQ 的 Broker 没有收到提交或者回滚的请求，Broker 会定期去生产者上反查这个事务对应的本地事务的状态，然后根据反查结果决定提交或者回滚这个事务。为了支撑这个事务反查机制，业务中需要实现一个反查本地事务状态的接口，告知 RocketMQ 本地事务是成功还是失败


## 消息可靠性
### 检测消息丢失
可以利用消息队列的有序性来验证是否有消息丢失。在 Producer 端，给每个发出的消息附加一个连续递增的序号，然后在 Consumer 端来检查这个序号的连续性。如果没有消息丢失，Consumer 收到消息的序号必然是连续递增的；如果检测到序号不连续，就表示消息丢失

可以利用这个拦截器机制，在 Producer 发送消息之前的拦截器中将序号注入到消息中，在 Consumer 收到消息的拦截器中检测序号的连续性

Kafka 只能保证分区上的消息有序，所以在发消息的时候必须要指定分区，并且在每个分区单独检测消息序号的连续性

如果系统中 Producer 是多实例的，由于并不好协调多个 Producer 之间的发送顺序，需要每个 Producer 分别生成各自的消息序号，并且需要附加上 Producer 的标识，在 Consumer 端按照每个 Producer 分别来检测序号的连续性

### 消息可靠传递
#### 生产阶段
通过请求确认机制，来保证消息的可靠传递：发消息方法时，消息队列的客户端会把消息发送到 Broker，Broker 收到消息后，会给客户端返回一个确认响应，表明消息已经收到了。客户端收到响应后，完成了一次正常消息的发送

只要 Producer 收到了 Broker 的确认响应，就可以保证消息在生产阶段不会丢失。有些消息队列在长时间没收到发送确认响应后，会自动重试，如果重试再失败，就会以返回值或者异常的方式告知用户。在编写发送消息代码时，正确处理返回值或者捕获异常，就可以保证这个阶段的消息不会丢失

同步发送
```java
try {
    RecordMetadata metadata = producer.send(record).get();
    System.out.println(" 消息发送成功。");
} catch (Throwable e) {
    System.out.println(" 消息发送失败!");
    System.out.println(e);
}
```

异步发送时，在回调方法里进行检查
```java
producer.send(record, (metadata, exception) -> {
    if (metadata != null) {
        System.out.println(" 消息发送成功。");
    } else {
        System.out.println(" 消息发送失败!");
        System.out.println(exception);
    }
}
```

#### 存储阶段
正常情况下，只要 Broker 在正常运行，就不会出现丢失消息的问题。但是如果 Broker 出现了故障，比如进程死掉或者服务器宕机，还是可能会丢失消息的

1. 对于单个节点的 Broker，配置 Broker 参数，在收到消息后，将消息写入磁盘后再给 Producer 返回确认响应，这样即使发生宕机，由于消息已经被写入磁盘，就不会丢失消息，恢复后还可以继续消费
2. 对于多个节点的 Broker 集群，将 Broker 集群配置成：至少将消息发送到 2 个以上的节点，再给客户端回复发送确认响应。这样当某个 Broker 宕机时，其他的 Broker 可以替代宕机的 Broker，也不会发生消息丢失

#### 消费阶段
客户端从 Broker 拉取消息后，执行用户的消费业务逻辑，成功后才会给 Broker 发送消费确认响应。如果 Broker 没有收到消费确认响应，下次拉消息的时候还会返回同一条消息，确保消息不会在 网络传输过程中丢失，也不会因为客户端在执行消费逻辑中出错导致丢失


## 重复消息
改造业务逻辑，将消费的业务逻辑设计成具备幂等性的操作

### 数据库唯一约束实现

### 为更新的数据设置前置条件
例如，给数据增加一个版本号属性。每次更数据前，比较当前数据的版本号是否和消息中的版本号一致，如果不一致就拒绝更新数据，更新数据的同时将版本号加 1

### 记录并检查操作
在发送消息时，给每条消息指定一个全局唯一的 id，消费时先根据这个 id 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费。


## 消息积压
### 发送端性能优化
对于发送消息的业务逻辑，只需要注意设置合适的并发和批量大小，就可以达到很好的发送性能

处理在线业务，注重处理时延，推荐通过并发来提升发送性能；离线分析业务，注重吞吐量，适合增加批次大小发送，可以用少量的并发就可以获得非常高的吞吐量

### 消费端性能优化

### 处理消息积压
如果是单位时间发送的消息增多，比如大促或者抢购，可以通过扩容消费端的实例数来提升总体的消费能力，如果短时间内没有足够的服务器资源进行扩容，只有将系统降级，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务

如果监控到消费变慢，先检查日志是否有大量的消费错误，然后通过打印堆栈信息，查看消费线程是否触发了死锁或者在等待某些资源


## kafka 高性能 IO
1. 使用批量消息提升服务端处理能力
2. 使用顺序读写提升磁盘 IO 性能
3. 利用 PageCache 加速消息读写
4. ZeroCopy：零拷贝技术


## 缓存策略
1. 更新数据的同时去更新缓存
2. 定期来更新全部缓存
3. 给缓存中的每个数据设置一个有效期，让它自然过期以达到更新的目的


## zookeeper
Kafka 主要使用 ZooKeeper 来保存它的元数据、监控 Broker 和分区的存活状态，并利用 ZooKeeper 来进行选举。

目前 Kafka 集群的可用性是严重依赖 zookeeper，如果需要部署大规模的 Kafka 集群，建议拆分成多个互相独立的小集群部署，每个小集群都使用一组独立的 zookeeper 提供服务。这样，每个 ZooKeeper 中存储的数据相对比较少，即使某个 zookeeper 集群故障，只会影响到一个小的 Kafka 集群

### broker 列表信息
/brokers/ids/[0...N] 保存 Kafka 的 Broker 信息，每个临时节点对应着一个在线的 Broker。Broker 启动后会创建一个临时节点，代表 Broker 已经加入集群可以提供服务了。节点内保存了 Broker 的地址、版本号、启动时间等的基本信息。如果 Broker 宕机或者与 ZooKeeper 集群失联了，这个临时节点也会随之消失

### 主题分区信息
/brokers/topics/ 保存主题和分区的信息。节点下面的每个子节点都是一个主题，节点的名称就是主题名称。每个主题节点下面都包含一个固定的 partitions 节点，pattitions 节点的子节点就是主题下的所有分区，节点名称就是分区编号。每个分区节点下面是一个名为 state 的临时节点，节点中保存着分区当前的 leader 和所有的 ISR 的 BrokerID。这个 state 临时节点是由这个分区当前的 Leader Broker 创建的。如果这个分区的 Leader Broker 宕机了，对应的这个 state 临时节点也会消失，直到新的 Leader 被选举出来，再次创建 state 临时节点

### 寻找 broker
先根据主题和分区，查找分区对应的 state 临时节点，然后货去 leader 副本的 BrokerID，然后再去查找 BrokerID 对应的临时节点，获取 Broker 真正的访问地址

Kafka 在每个 Broker 中都维护了一份和 ZooKeeper 中一样的元数据缓存，因此并不是每次客户端请求元数据就去读一次 ZooKeeper。由于 ZooKeeper 提供了 Watcher 这种监控机制，Kafka 可以感知到 ZooKeeper 中的元数据变化，从而及时更新 Broker 中的元数据缓存

### zookeeper 缺点
zooKeeper 只适合存放少量的数据。依据服务器配置的不同，ZooKeeper 在写入超过几百 MB 数据之后，性能和稳定性都会严重下降
